{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=\"sk-ecc1b4f705dc49f8ab3bd3ce5fc9b0a3\", base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_file(file_path, n):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    length = len(content)\n",
    "    chunk_size = length // n\n",
    "    chunks = [content[i:i + chunk_size] for i in range(0, length, chunk_size)]\n",
    "    if len(chunks) > n:\n",
    "        chunks[-2] += chunks[-1]\n",
    "        chunks.pop()\n",
    "    return chunks\n",
    "\n",
    "def get_gpt_responses(chunks, sample, prompt0):\n",
    "    responses = []\n",
    "    i = 0\n",
    "    for chunk in chunks:\n",
    "        prompt = chunk + prompt0 \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sample[\"system\"]},\n",
    "                {\"role\": \"user\", \"content\": sample[\"user\"]},\n",
    "                {\"role\": \"assistant\", \"content\": sample[\"assistant\"]},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            stream=False,\n",
    "            temperature=1.0\n",
    "        )\n",
    "        responses.append(response.choices[0].message.content.strip())\n",
    "        i += 1\n",
    "        print(f\"Chunk {i} of {len(chunks)} processed.\")\n",
    "    return responses\n",
    "\n",
    "def main(file_path, n, sample_path, prompt0, print_chunk = False):\n",
    "    with open(sample_path, 'r', encoding='utf-8') as sample_file:\n",
    "        sample = json.load(sample_file)\n",
    "    \n",
    "    chunks = split_file(file_path, n)\n",
    "    responses = []\n",
    "    i = 0\n",
    "    for chunk in chunks:\n",
    "        prompt = chunk + prompt0 \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sample[\"system\"]},\n",
    "                {\"role\": \"user\", \"content\": sample[\"user\"]},\n",
    "                {\"role\": \"assistant\", \"content\": sample[\"assistant\"]},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            stream=False,\n",
    "            temperature=1.0\n",
    "        )\n",
    "        responses.append(response.choices[0].message.content.strip())\n",
    "        i += 1\n",
    "        if print_chunk:\n",
    "            print(f\"Chunk {i} of {len(chunks)} processed.\")\n",
    "    return responses\n",
    "\n",
    "def main2(file_path, n, prompt0, print_chunk = False):\n",
    "    chunks = split_file(file_path, n)\n",
    "    responses = []\n",
    "    i = 0\n",
    "    for chunk in chunks:\n",
    "        prompt = chunk + prompt0 \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Hello! I'm an AI assistant. How can I help you today?\"},\n",
    "                {\"role\": \"user\", \"content\": \"I need help with something.\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Sure! I'll do my best to help you.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            stream=False,\n",
    "            temperature=1.0\n",
    "        )\n",
    "        responses.append(response.choices[0].message.content.strip())\n",
    "        i += 1\n",
    "        if print_chunk:\n",
    "            print(f\"Chunk {i} of {len(chunks)} processed.\")\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成词汇\n",
    "耗时1min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**rural : of, relating to, or characteristic of the country as opposed to the city.**\n",
      "puny : small and weak in size or strength\n",
      "Hellhole : A place that is extremely unpleasant, dirty, or uncomfortable, often due to being overcrowded or having poor conditions.\n",
      "**goggle-eyed : wide-eyed with surprise or amazement**\n",
      "**dangling :** Hanging loosely or limply; not fixed firmly or supported.\n",
      "rippled : (verb) to form or cause to form a series of small waves or undulations.\n",
      "**rutted :** having grooves or channels, typically caused by erosion or wear.\n",
      "Shimmering : Glistening or sparkling with a soft, wavering light.\n",
      "Scuba : A device for supplying a diver with air to breathe underwater, consisting of a tank of compressed air and a breathing apparatus.\n",
      "swallow : a small, quick gulp or movement, often used to describe the action of taking food or liquid down the throat.\n",
      "Enchanted : Delightfully charming or alluring, often used to describe something that seems to have magic or supernatural qualities.\n",
      "**shinnying :** moving upward along a surface by gripping it with the legs and/or arms\n",
      "Exhilaration : A feeling of great happiness and excitement.\n",
      "Regicide : The act of killing a king or ruler.\n",
      "obsessed : extremely interested or preoccupied with something\n",
      "Guardian : A person who protects or takes care of something or someone.\n",
      "exiled : forced to leave a place or situation, often permanently\n",
      "Razor-blading : Using a razor blade to scrape or remove something, typically paint or adhesive.\n",
      "Alcove : A recess or small room, often partially enclosed, as in a larger room or hall.\n",
      "Stew : A dish of meat and vegetables cooked slowly in liquid.\n",
      "Wheedling : Persuading or attempting to persuade someone by using persistent coaxing or flattery.\n",
      "gunnysack : a coarse bag made of burlap or gunny cloth, used for packing or storing goods.\n",
      "Cleats : Metal or plastic spikes attached to the soles of shoes to provide traction on grass or wet surfaces.\n",
      "repented : felt remorse or regret for a past action\n",
      "Smithsonian : A large complex of museums and research centers in Washington, D.C., operated by the U.S. government, named after James Smithson, who left funds to the U.S. for creating an establishment for the \"increase and diffusion of knowledge.\"\n",
      "Vaulted : having a high arched roof or ceiling.\n",
      "Hurtling : Moving at high speed in a headlong manner.\n",
      "knocker : a device attached to a door, typically in the shape of a ball or ring, that is used to strike the door to signal the desire to enter.\n",
      "Cremated : Reduced to ashes, especially by fire, as part of a funeral process.\n",
      "Wreath : A circular arrangement of flowers, leaves, or stems, often used as a decoration or symbol of remembrance.\n",
      "Smarter : More intelligent or clever.\n",
      "U-Haul : A brand name for a company that rents trucks and trailers for moving purposes, often used generically to refer to any rental moving truck.\n",
      "---------------\n",
      "Intoxicated : Drunk\n",
      "unhandy : inconvenient\n",
      "slooching : squishing\n",
      "hellhole : extremely unpleasant place\n",
      "goggle-eyed : wide-eyed\n",
      "Proverbial : Well-known\n",
      "stop-action : pause-like\n",
      "Rippled : Waved\n",
      "Clabber : Sour milk\n",
      "dumb : stupid\n",
      "prissily : in a prim or overly proper manner\n",
      "Reassessing : Evaluating\n",
      "liable : likely\n",
      "broad-beamed : wide-hipped\n",
      "enchanted : magical\n",
      "Mischief : Playfulness\n",
      "Hippies : Unconventional people\n",
      "Cross-your-heart-and-hope-to-die : A solemn promise\n",
      "Regicide : Killing a king\n",
      "heavy : difficult\n",
      "foundling : abandoned child\n",
      "Terabithian : Terabithia-like\n",
      "Squenched : Squeezed\n",
      "glowingly : enthusiastically\n",
      "Razor-blading : Scraping\n",
      "alcove : hidden recess\n",
      "Blabbed : Spilled\n",
      "complacent : satisfied\n",
      "Decent : Proper, respectable\n",
      "flounced : moved with a showy, exaggerated motion\n",
      "Cleats : Spiked shoes\n",
      "undigested : not digested\n",
      "plodding : walking slowly and with effort\n",
      "Tippytoes : Toes\n",
      "glisten : shine\n",
      "baripity : sound of the pickup\n",
      "lopsided : uneven\n",
      "Brood : Group\n",
      "miz : miss\n",
      "Cremated : Turned to ashes\n",
      "Dumb : Silly\n",
      "bongoing : pounding\n",
      "Hallmark : Greeting card\n",
      "knighted : honored\n"
     ]
    }
   ],
   "source": [
    "# 调用主函数\n",
    "prompt1 = \"\\n\\n Find a new word in the text above and return its English definition in the format 'xxx : xxx' ,Please choose nouns, adjectives, adverbs, or verbs\"\n",
    "prompt2 = \"\\n\\n Find a word in the text above which is rare but esay to guess by the text, and return your brief guess in the format 'xxx : xxx' ,Please choose nouns, adjectives, adverbs, or verbs\"\n",
    "a = main('a.txt', 32, 'sample1.json' , prompt1)\n",
    "for i in a:\n",
    "    print(i)\n",
    "print(\"---------------\") \n",
    "a = main('a.txt', 44, 'sample2.json' , prompt2) \n",
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### questions in RR\n",
    "###### 这个效果不好,别用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = \"If you don't fully understand the story, please ask 5 Yes/No questions with the about the story. It is best if each of questions consists of multiple logically related questions. no longer than 70 words in a.Please express it in a question\"\n",
    "a = main('a.txt', 1, 'sample3.json' , prompt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ideas in RR\n",
    "###### 这个效果不好,别用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4 = \"\\n\\n Give me 3 ideas from this reading that would be interesting to discuss,no longer than 70 words \"\n",
    "a = main2('a.txt', 1, prompt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一键生成小说大意(人物介绍+切片分段大意(中英文))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 of 45 processed.\n",
      "Chunk 2 of 45 processed.\n",
      "Chunk 3 of 45 processed.\n",
      "Chunk 4 of 45 processed.\n",
      "Chunk 5 of 45 processed.\n",
      "Chunk 6 of 45 processed.\n",
      "Chunk 7 of 45 processed.\n",
      "Chunk 8 of 45 processed.\n",
      "Chunk 9 of 45 processed.\n",
      "Chunk 10 of 45 processed.\n",
      "Chunk 11 of 45 processed.\n",
      "Chunk 12 of 45 processed.\n",
      "Chunk 13 of 45 processed.\n",
      "Chunk 14 of 45 processed.\n",
      "Chunk 15 of 45 processed.\n",
      "Chunk 16 of 45 processed.\n",
      "Chunk 17 of 45 processed.\n",
      "Chunk 18 of 45 processed.\n",
      "Chunk 19 of 45 processed.\n",
      "Chunk 20 of 45 processed.\n",
      "Chunk 21 of 45 processed.\n",
      "Chunk 22 of 45 processed.\n",
      "Chunk 23 of 45 processed.\n",
      "Chunk 24 of 45 processed.\n",
      "Chunk 25 of 45 processed.\n",
      "Chunk 26 of 45 processed.\n",
      "Chunk 27 of 45 processed.\n",
      "Chunk 28 of 45 processed.\n",
      "Chunk 29 of 45 processed.\n",
      "Chunk 30 of 45 processed.\n",
      "Chunk 31 of 45 processed.\n",
      "Chunk 32 of 45 processed.\n",
      "Chunk 33 of 45 processed.\n",
      "Chunk 34 of 45 processed.\n",
      "Chunk 35 of 45 processed.\n",
      "Chunk 36 of 45 processed.\n",
      "Chunk 37 of 45 processed.\n",
      "Chunk 38 of 45 processed.\n",
      "Chunk 39 of 45 processed.\n",
      "Chunk 40 of 45 processed.\n",
      "Chunk 41 of 45 processed.\n",
      "Chunk 42 of 45 processed.\n",
      "Chunk 43 of 45 processed.\n",
      "Chunk 44 of 45 processed.\n",
      "Chunk 45 of 45 processed.\n",
      "输出已保存到 Jocab Have I loved.md\n"
     ]
    }
   ],
   "source": [
    "# 设置文件名\n",
    "title_of_your_md = \"Jocab Have I loved\"\n",
    "md_file_name = f\"{title_of_your_md}.md\"\n",
    "\n",
    "# 准备提示\n",
    "prompt5 = \"\\n\\n  用中文帮我理一下这本小说的人物和人际关系\"\n",
    "prompt6 = \"\\n\\n  用中文给这一段做一个故事梗概,多补充一点细节分点列出,并在你认为重点的地方给出英文对(请你注意格式,对照的地方一句中文对应一句英文)\"\n",
    "\n",
    "with open(md_file_name, 'w', encoding='utf-8') as md_file:\n",
    "    md_file.write(f\"# {title_of_your_md}\\n\\n\")\n",
    "    md_file.write(\"## 人物和人际关系\\n\\n\")\n",
    "    a = main2('a.txt', 1, prompt5)\n",
    "    for i in a:\n",
    "        md_file.write(i + \"\\n\")\n",
    "    md_file.write(\"<br/>\\n\\n\")\n",
    "    md_file.write(\"## 故事梗概\\n\\n\")\n",
    "    a = main('a.txt', 45, 'sample_for_preparing_quiz.json', prompt6, True)\n",
    "    j = 0\n",
    "    for i in a:\n",
    "        j += 1\n",
    "        md_file.write(f\"### 分段{j}\\n\")\n",
    "        md_file.write(i + \"\\n\")\n",
    "        md_file.write(\"<br/>\\n\")\n",
    "\n",
    "print(f\"输出已保存到 {md_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text-sample转化器(开发用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiline_text = \"\"\" \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 将多行文字转换为一行，换行符用\\n转义\n",
    "single_line_text = multiline_text.replace('\\n', '\\\\n')\n",
    "\n",
    "# 将结果写入到文件 b.txt\n",
    "with open('b.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(single_line_text)\n",
    "\n",
    "print(\"文本已经写入到 b.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

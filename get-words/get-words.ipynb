{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=\"sk-988eb73686e24998a62dd62cdfdc19ac\", base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_file(file_path, n):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    length = len(content)\n",
    "    chunk_size = length // n\n",
    "    chunks = [content[i:i + chunk_size] for i in range(0, length, chunk_size)]\n",
    "    if len(chunks) > n:\n",
    "        chunks[-2] += chunks[-1]\n",
    "        chunks.pop()\n",
    "    return chunks\n",
    "\n",
    "def get_gpt_responses(chunks, sample, prompt0):\n",
    "    responses = []\n",
    "    i = 0\n",
    "    for chunk in chunks:\n",
    "        prompt = chunk + prompt0 \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sample[\"system\"]},\n",
    "                {\"role\": \"user\", \"content\": sample[\"user\"]},\n",
    "                {\"role\": \"assistant\", \"content\": sample[\"assistant\"]},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            stream=False,\n",
    "            temperature=1.0\n",
    "        )\n",
    "        responses.append(response.choices[0].message.content.strip())\n",
    "        i += 1\n",
    "        print(f\"Chunk {i} of {len(chunks)} processed.\")\n",
    "    return responses\n",
    "\n",
    "def main(file_path, n, sample_path, prompt0, print_chunk = False):\n",
    "    with open(sample_path, 'r', encoding='utf-8') as sample_file:\n",
    "        sample = json.load(sample_file)\n",
    "    \n",
    "    chunks = split_file(file_path, n)\n",
    "    responses = []\n",
    "    i = 0\n",
    "    for chunk in chunks:\n",
    "        prompt = chunk + prompt0 \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sample[\"system\"]},\n",
    "                {\"role\": \"user\", \"content\": sample[\"user\"]},\n",
    "                {\"role\": \"assistant\", \"content\": sample[\"assistant\"]},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            stream=False,\n",
    "            temperature=1.0\n",
    "        )\n",
    "        responses.append(response.choices[0].message.content.strip())\n",
    "        i += 1\n",
    "        if print_chunk:\n",
    "            print(f\"Chunk {i} of {len(chunks)} processed.\")\n",
    "    return responses\n",
    "\n",
    "def main2(file_path, n, prompt0, print_chunk = False):\n",
    "    chunks = split_file(file_path, n)\n",
    "    responses = []\n",
    "    i = 0\n",
    "    for chunk in chunks:\n",
    "        prompt = chunk + prompt0 \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Hello! I'm an AI assistant. How can I help you today?\"},\n",
    "                {\"role\": \"user\", \"content\": \"I need help with something.\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Sure! I'll do my best to help you.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            stream=False,\n",
    "            temperature=1.0\n",
    "        )\n",
    "        responses.append(response.choices[0].message.content.strip())\n",
    "        i += 1\n",
    "        if print_chunk:\n",
    "            print(f\"Chunk {i} of {len(chunks)} processed.\")\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成词汇\n",
    "耗时1min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**creepy : causing an unpleasant feeling of fear or unease**\n",
      "Faun : A mythical creature from Roman mythology, similar to a satyr, with the upper body of a human and the lower body of a goat, often associated with woods and forests.\n",
      "Nymphs : In mythology, Nymphs are minor female nature deities often associated with a particular location or landform. They are typically depicted as beautiful, young maidens.\n",
      "Mantelpiece : A structure above a fireplace, often used for displaying ornaments or pictures.\n",
      "Faun : A half-human, half-goat creature from Roman mythology, often associated with forests and woods.\n",
      "Faun : A half-human, half-goat creature from Roman mythology, often associated with woods and fields.\n",
      "harness : The equipment and accessories used to control and guide a horse or other animal, typically for riding or pulling a vehicle.\n",
      "inquisitive : eager to know or learn something\n",
      "Naiad : A nymph associated with bodies of water, such as rivers, springs, or lakes.\n",
      "nastiest : most unpleasant or unkind\n",
      "Faun : A rustic forest god in Roman mythology with the upper body of a human and the lower body of a goat, associated with fertility and the countryside.\n",
      "cramped : uncomfortable because of being too small or narrow\n",
      "Premises : A house or building, including its land and outbuildings, occupied by a business or considered in an official context.\n",
      "fraternizing : associating or mingling as brothers or on a brotherly basis with one another\n",
      "---------------\n",
      "steadily : continuously\n",
      "moth-balls : small balls used to repel moths\n",
      "Faun : Mythical creature resembling a man with goat-like features\n",
      "Faun : Mythical woodland creature\n",
      "Dryads : Tree spirits\n",
      "Cloven : Split\n",
      "Faun : Mythical woodland creature\n",
      "jolly : happy\n",
      "Pax : Peace\n",
      "flaming : burning\n",
      "enchanted : magic\n",
      "courts : rooms\n",
      "Dryads : Tree spirits\n",
      "sulky : moody\n",
      "Faun : Mythical woodland creature\n",
      "jeering : mocking\n",
      "filthy : dirty\n",
      "Faun : A mythical woodland creature with the upper body of a human and the lower body of a goat\n",
      "Chatelaine : Estate manager\n",
      "larder : storage for food\n"
     ]
    }
   ],
   "source": [
    "# 调用主函数\n",
    "prompt1 = \"\\n\\n Find a new word in the text above and return its English definition in the format 'xxx : xxx' ,Please choose nouns, adjectives, adverbs, or verbs\"\n",
    "prompt2 = \"\\n\\n Find a word in the text above which is rare but esay to guess by the text, and return your brief guess in the format 'xxx : xxx' ,Please choose nouns, adjectives, adverbs, or verbs\"\n",
    "a = main('a.txt', 14, 'sample1.json' , prompt1)\n",
    "for i in a:\n",
    "    print(i)\n",
    "print(\"---------------\") \n",
    "a = main('a.txt', 20, 'sample2.json' , prompt2) \n",
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### questions in RR\n",
    "###### 这个效果不好,别用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = \"If you don't fully understand the story, please ask 5 Yes/No questions with the about the story. It is best if each of questions consists of multiple logically related questions. no longer than 70 words in a.Please express it in a question\"\n",
    "a = main('a.txt', 1, 'sample3.json' , prompt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ideas in RR\n",
    "###### 这个效果不好,别用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4 = \"\\n\\n Give me 3 ideas from this reading that would be interesting to discuss,no longer than 70 words \"\n",
    "a = main2('a.txt', 1, prompt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一键生成小说大意(人物介绍+切片分段大意(中英文))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 of 30 processed.\n",
      "Chunk 2 of 30 processed.\n",
      "Chunk 3 of 30 processed.\n",
      "Chunk 4 of 30 processed.\n",
      "Chunk 5 of 30 processed.\n",
      "Chunk 6 of 30 processed.\n",
      "Chunk 7 of 30 processed.\n",
      "Chunk 8 of 30 processed.\n",
      "Chunk 9 of 30 processed.\n",
      "Chunk 10 of 30 processed.\n",
      "Chunk 11 of 30 processed.\n",
      "Chunk 12 of 30 processed.\n",
      "Chunk 13 of 30 processed.\n",
      "Chunk 14 of 30 processed.\n",
      "Chunk 15 of 30 processed.\n",
      "Chunk 16 of 30 processed.\n",
      "Chunk 17 of 30 processed.\n",
      "Chunk 18 of 30 processed.\n",
      "Chunk 19 of 30 processed.\n",
      "Chunk 20 of 30 processed.\n",
      "Chunk 21 of 30 processed.\n",
      "Chunk 22 of 30 processed.\n",
      "Chunk 23 of 30 processed.\n",
      "Chunk 24 of 30 processed.\n",
      "Chunk 25 of 30 processed.\n",
      "Chunk 26 of 30 processed.\n",
      "Chunk 27 of 30 processed.\n",
      "Chunk 28 of 30 processed.\n",
      "Chunk 29 of 30 processed.\n",
      "Chunk 30 of 30 processed.\n",
      "输出已保存到 The Lion, The Witch And The Wardrobe 1-6.md\n"
     ]
    }
   ],
   "source": [
    "# 设置文件名\n",
    "title_of_your_md = \"The Lion, The Witch And The Wardrobe 1-6\"\n",
    "md_file_name = f\"{title_of_your_md}.md\"\n",
    "\n",
    "# 准备提示\n",
    "prompt5 = \"\\n\\n  用中文帮我理一下这本小说的人物和人际关系\"\n",
    "prompt6 = \"\\n\\n  用中文给这一段做一个故事梗概,多补充一点细节分点列出,并在你认为重点的地方给出英文对(请你注意格式,对照的地方一句中文对应一句英文)\"\n",
    "\n",
    "with open(md_file_name, 'w', encoding='utf-8') as md_file:\n",
    "    md_file.write(f\"# {title_of_your_md}\\n\\n\")\n",
    "    md_file.write(\"## 人物和人际关系\\n\\n\")\n",
    "    a = main2('a.txt', 1, prompt5)\n",
    "    for i in a:\n",
    "        md_file.write(i + \"\\n\")\n",
    "    md_file.write(\"<br/>\\n\\n\")\n",
    "    md_file.write(\"## 故事梗概\\n\\n\")\n",
    "    a = main('a.txt', 30, 'sample_for_preparing_quiz.json', prompt6, True)\n",
    "    j = 0\n",
    "    for i in a:\n",
    "        j += 1\n",
    "        md_file.write(f\"### 分段{j}\\n\")\n",
    "        md_file.write(i + \"\\n\")\n",
    "        md_file.write(\"<br/>\\n\")\n",
    "\n",
    "print(f\"输出已保存到 {md_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text-sample转化器(开发用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本已经写入到 b.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "multiline_text = \"\"\" \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 将多行文字转换为一行，换行符用\\n转义\n",
    "single_line_text = multiline_text.replace('\\n', '\\\\n')\n",
    "\n",
    "# 将结果写入到文件 b.txt\n",
    "with open('b.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(single_line_text)\n",
    "\n",
    "print(\"文本已经写入到 b.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

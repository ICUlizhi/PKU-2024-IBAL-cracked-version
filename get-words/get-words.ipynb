{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "# 我有时候想不起来改这个key,请自觉换成您自己的\n",
    "client = OpenAI(api_key=\"sk-ecc1b4f705dc49f8ab3bd3ce5fc9b0a3\", base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_file(file_path, n):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    length = len(content)\n",
    "    chunk_size = length // n\n",
    "    chunks = [content[i:i + chunk_size] for i in range(0, length, chunk_size)]\n",
    "    if len(chunks) > n:\n",
    "        chunks[-2] += chunks[-1]\n",
    "        chunks.pop()\n",
    "    return chunks\n",
    "\n",
    "def get_gpt_responses(chunks, sample, prompt0):\n",
    "    responses = []\n",
    "    i = 0\n",
    "    for chunk in chunks:\n",
    "        prompt = chunk + prompt0 \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sample[\"system\"]},\n",
    "                {\"role\": \"user\", \"content\": sample[\"user\"]},\n",
    "                {\"role\": \"assistant\", \"content\": sample[\"assistant\"]},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            stream=False,\n",
    "            temperature=1.0\n",
    "        )\n",
    "        responses.append(response.choices[0].message.content.strip())\n",
    "        i += 1\n",
    "        print(f\"Chunk {i} of {len(chunks)} processed.\")\n",
    "    return responses\n",
    "\n",
    "def main(file_path, n, sample_path, prompt0, print_chunk = False):\n",
    "    with open(sample_path, 'r', encoding='utf-8') as sample_file:\n",
    "        sample = json.load(sample_file)\n",
    "    \n",
    "    chunks = split_file(file_path, n)\n",
    "    responses = []\n",
    "    i = 0\n",
    "    for chunk in chunks:\n",
    "        prompt = chunk + prompt0 \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sample[\"system\"]},\n",
    "                {\"role\": \"user\", \"content\": sample[\"user\"]},\n",
    "                {\"role\": \"assistant\", \"content\": sample[\"assistant\"]},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            stream=False,\n",
    "            temperature=1.0\n",
    "        )\n",
    "        responses.append(response.choices[0].message.content.strip())\n",
    "        i += 1\n",
    "        if print_chunk:\n",
    "            print(f\"Chunk {i} of {len(chunks)} processed.\")\n",
    "    return responses\n",
    "\n",
    "def main2(file_path, n, prompt0, print_chunk = False):\n",
    "    chunks = split_file(file_path, n)\n",
    "    responses = []\n",
    "    i = 0\n",
    "    for chunk in chunks:\n",
    "        prompt = chunk + prompt0 \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Hello! I'm an AI assistant. How can I help you today?\"},\n",
    "                {\"role\": \"user\", \"content\": \"I need help with something.\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Sure! I'll do my best to help you.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            stream=False,\n",
    "            temperature=1.0\n",
    "        )\n",
    "        responses.append(response.choices[0].message.content.strip())\n",
    "        i += 1\n",
    "        if print_chunk:\n",
    "            print(f\"Chunk {i} of {len(chunks)} processed.\")\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成词汇\n",
    "耗时1min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Humbug : nonsense or deception\n",
      "Residuary : remaining after death\n",
      "Veneration : deep respect\n",
      "Facetious : joking in a light-hearted way\n",
      "Poulterers' : sellers of poultry\n",
      "broadwise : wide direction\n",
      "tights : close-fitting leg coverings\n",
      "ponderous : heavy or weighty\n",
      "abode : place of residence\n",
      "preposterous : highly unreasonable\n",
      "reclamation : restoring to better state\n",
      "Deal : simple wooden furniture\n",
      "Welsh wig : old-fashioned hairpiece\n",
      "Stomach-aches : intense tuning sounds\n",
      "Even-handed : fair and impartial\n",
      "Pommel : strike lightly\n",
      "Extinguisher-cap : cap used to smother flames\n",
      "Glorious : extremely beautiful\n",
      "Apoplectic : relating to excessive fatness\n",
      "barnacle : marine organism that attaches to surfaces\n",
      "Bustle : lively commotion\n",
      "adamant : unyielding, unchangeable\n",
      "Furze : thorny shrub\n",
      "Loophole : narrow opening\n",
      "mouldy : old and musty\n",
      "Almshouse : charitable housing\n",
      "Prostrate : lying flat\n",
      "Excrescence : abnormal growth\n",
      "Frowsy : dirty and untidy\n",
      "Calico : coarse cotton cloth\n",
      "Griping : tightly gripping, intense\n",
      "\"reconciled : made peace with\"\n",
      "Replete : filled to the full\n",
      "Laocoön : entangled in struggle\n",
      "Blithe : cheerful, lighthearted\n",
      "Strait-waistcoat : a garment used to restrain someone\n",
      "Barrister : legal advocate\n",
      "Alms : charitable donations\n",
      "excrescence : abnormal growth\n",
      "twelfth-cakes : fruit cake for Twelfth Night\n"
     ]
    }
   ],
   "source": [
    "# 调用主函数\n",
    "prompt1 = \"\\n\\n Find a new word in the text above and return its English definition in the format 'xxx : xxx' ,Please choose nouns, adjectives, adverbs, or verbs.Don't choose proper nouns\"\n",
    "prompt2 = \"\\n\\n Find a word in the text above which is rare but esay to guess by the text, and return your brief guess in the format 'xxx : xxx' .\\n Please choose nouns, adjectives, adverbs, or verbs.\\n Don't choose proper nouns.\\n Don't choose too obscure vocabulary \\n brief guess consists of 3-7 words!\\n Please make your guess as different as possible from the dictionary definition, so that you can guess incorrectly\"\n",
    "'''\n",
    "a = main('a.txt', 32, 'sample1.json' , prompt1)\n",
    "for i in a:\n",
    "    print(i)\n",
    "'''\n",
    "print(\"---------------\") \n",
    "a = main('a.txt', 40, 'sample2.json' , prompt2) \n",
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### questions in RR\n",
    "###### 这个效果不好,别用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = \"If you don't fully understand the story, please ask 5 Yes/No questions with the about the story. It is best if each of questions consists of multiple logically related questions. no longer than 70 words in a.Please express it in a question\"\n",
    "a = main('a.txt', 1, 'sample3.json' , prompt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ideas in RR\n",
    "###### 这个效果不好,别用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4 = \"\\n\\n Give me 3 ideas from this reading that would be interesting to discuss,no longer than 70 words \"\n",
    "a = main2('a.txt', 1, prompt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一键生成小说大意(人物介绍+切片分段大意(中英文))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 of 30 processed.\n",
      "Chunk 2 of 30 processed.\n",
      "Chunk 3 of 30 processed.\n",
      "Chunk 4 of 30 processed.\n",
      "Chunk 5 of 30 processed.\n",
      "Chunk 6 of 30 processed.\n",
      "Chunk 7 of 30 processed.\n",
      "Chunk 8 of 30 processed.\n",
      "Chunk 9 of 30 processed.\n",
      "Chunk 10 of 30 processed.\n",
      "Chunk 11 of 30 processed.\n",
      "Chunk 12 of 30 processed.\n",
      "Chunk 13 of 30 processed.\n",
      "Chunk 14 of 30 processed.\n",
      "Chunk 15 of 30 processed.\n",
      "Chunk 16 of 30 processed.\n",
      "Chunk 17 of 30 processed.\n",
      "Chunk 18 of 30 processed.\n",
      "Chunk 19 of 30 processed.\n",
      "Chunk 20 of 30 processed.\n",
      "Chunk 21 of 30 processed.\n",
      "Chunk 22 of 30 processed.\n",
      "Chunk 23 of 30 processed.\n",
      "Chunk 24 of 30 processed.\n",
      "Chunk 25 of 30 processed.\n",
      "Chunk 26 of 30 processed.\n",
      "Chunk 27 of 30 processed.\n",
      "Chunk 28 of 30 processed.\n",
      "Chunk 29 of 30 processed.\n",
      "Chunk 30 of 30 processed.\n",
      "输出已保存到 A Christmas Carol.md\n"
     ]
    }
   ],
   "source": [
    "# 设置文件名\n",
    "title_of_your_md = \"A Christmas Carol\"\n",
    "md_file_name = f\"{title_of_your_md}.md\"\n",
    "\n",
    "# 准备提示\n",
    "prompt5 = \"\\n\\n  用中文帮我理一下这本小说的人物和人际关系\"\n",
    "prompt6 = \"\\n\\n  用中文给这一段做一个故事梗概,多补充一点细节分点列出,并在你认为重点的地方给出英文对(请你注意格式,对照的地方一句中文对应一句英文)\"\n",
    "\n",
    "with open(md_file_name, 'w', encoding='utf-8') as md_file:\n",
    "    md_file.write(f\"# {title_of_your_md}\\n\\n\")\n",
    "    md_file.write(\"## 人物和人际关系\\n\\n\")\n",
    "    a = main2('a.txt', 1, prompt5)\n",
    "    for i in a:\n",
    "        md_file.write(i + \"\\n\")\n",
    "    md_file.write(\"<br/>\\n\\n\")\n",
    "    md_file.write(\"## 故事梗概\\n\\n\")\n",
    "    a = main('a.txt', 30, 'sample_for_preparing_quiz.json', prompt6, True)\n",
    "    j = 0\n",
    "    for i in a:\n",
    "        j += 1\n",
    "        md_file.write(f\"### 分段{j}\\n\")\n",
    "        md_file.write(i + \"\\n\")\n",
    "        md_file.write(\"<br/>\\n\")\n",
    "\n",
    "print(f\"输出已保存到 {md_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text-sample转化器(开发用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiline_text = \"\"\" \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 将多行文字转换为一行，换行符用\\n转义\n",
    "single_line_text = multiline_text.replace('\\n', '\\\\n')\n",
    "\n",
    "# 将结果写入到文件 b.txt\n",
    "with open('b.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(single_line_text)\n",
    "\n",
    "print(\"文本已经写入到 b.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
